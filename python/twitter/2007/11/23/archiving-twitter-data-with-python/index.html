<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Archiving Twitter data with Python &middot; More than seven
    
  </title>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-435455-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>



  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
   <script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?zoneid=1673&serve=C6AILKT&placement=morethansevennet" id="_carbonads_js"></script>

   <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          More than seven
        </a>
      </h1>
      <p class="lead">Writing about code mainly. Occasional other topics. Made by <a href="https://twitter.com/garethr">@garethr</a>.</p>
    </div>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Archiving Twitter data with Python</h1>
  <span class="post-date">23 Nov 2007</span>
  <p><a href="http://www.al3x.net/">Alex</a> from <a href="http://twitter.com">Twitter</a> just got round to adding the ability to export your entire archive of tweets via the <a href="http://groups.google.com/group/twitter-development-talk/web/api-documentation"><span class="caps">API</span></a>. A few people on the mailing list had been asking for this for a while so good to see it get released.</p>
<p>I couldn&#8217;t resist knocking together a very quick and simple Python script to go off and get all your tweets, presented here for anyone else to play around with. Note that simple, fast and works on my machine were watchwords here. Don&#8217;t expect fancy parameters, much error handling or artificial intelligence.</p>
<% syntax_colorize :python, type=:coderay do %>
import urllib2
username = '<YOUR USERNAME>'
password = '<YOUR PASSWORD>'
format = 'json' # json or xml
filename = 'archive.json' # filename of the archive
tweets = 164 # number of tweets
pages = (int(float(tweets)/float(80)))+1
auth = urllib2.HTTPPasswordMgrWithDefaultRealm()
auth.add_password(None, 'http://twitter.com/account/', username, password)
authHandler = urllib2.HTTPBasicAuthHandler(auth)
opener = urllib2.build_opener(authHandler)
urllib2.install_opener(opener) 
i = 1
response = ''
print 'Downloading tweets. Note that this may take some time'
while i <= pages:
    request = urllib2.Request('http://twitter.com/statuses/user_timeline/account.' \
    + format + '?page=' + str(i))
    response = response + urllib2.urlopen(request).read()
    i = i + 1
handle = open(filename,"w")
handle.write(response)
handle.close()
print 'Archived ' + str(tweets) + ' of ' + username + \
'\'s tweets to ' + filename
<% end %>
<p>The main thing to note here though is the ideal of <a href="http://www.dataportability.org/">data portability</a>. Let&#8217;s just say I wanted to move to Jaiku or Pownce instead of Twitter, but didn&#8217;t want to lose all that data. If I can knock up an export script in half an hour then all you need are import data <span class="caps">API</span> calls and a little more scripting.</p>
<p>As it is, I&#8217;m more interesting in seeing what I can do with my data now I can get at it. <a href="http://suda.co.uk">Brian</a> just suggested a <a href="http://simile.mit.edu/timeline/">quick visualisation tool</a> (which already eats <span class="caps">JSON</span>) and I&#8217;d already been thinking about <a href="http://morethanseven.net/posts/pygunfog/">language analysis</a> and maybe having a look at <a href="http://www.apml.org/"><span class="caps">APML</span></a> some more. Open data is simply more fun.</p>
</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/work/gds/2014/07/20/leaving-gds-never-easy/">
            Leaving GDS never easy
            <small>20 Jul 2014</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/security/2014/06/23/using-owasp-zap-from-the-command-line/">
            Using OWASP ZAP from the command line
            <small>23 Jun 2014</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/consul/2014/04/25/consul/">
            Consul, DNS and Dnsmasq
            <small>25 Apr 2014</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

    </div>

  </body>
</html>
